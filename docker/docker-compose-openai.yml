version: '3.8'

# =============================================================================
# Docker Compose - Versão com Embeddings OpenAI
# =============================================================================
# Esta versão usa a API da OpenAI para geração de embeddings.
# Requer OPENAI_API_KEY configurada no arquivo .env na raiz do projeto.
#
# Uso:
#   docker compose -f docker-compose-openai.yml up -d
# =============================================================================

# Carrega variáveis do .env da raiz do projeto
x-env-file: &env-file
  env_file:
    - ../.env

services:
  # PostgreSQL - Banco de dados principal
  postgres:
    image: postgres:15-alpine
    container_name: prompt_optimizer_postgres
    environment:
      POSTGRES_USER: prompt_optimizer
      POSTGRES_PASSWORD: prompt_optimizer_secret
      POSTGRES_DB: prompt_optimizer
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U prompt_optimizer"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - prompt_optimizer_network

  # Redis - Cache para prompts otimizados
  redis:
    image: redis:7-alpine
    container_name: prompt_optimizer_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - prompt_optimizer_network

  # Weaviate - Busca vetorial com OpenAI embeddings
  weaviate:
    <<: *env-file
    image: semitechnologies/weaviate:1.24.1
    container_name: prompt_optimizer_weaviate
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'
      ENABLE_MODULES: 'text2vec-openai,generative-openai'
      # OpenAI API Key para embeddings
      OPENAI_APIKEY: ${OPENAI_API_KEY}
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - weaviate_data:/var/lib/weaviate
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8080/v1/.well-known/ready || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    networks:
      - prompt_optimizer_network

  # API FastAPI
  api:
    <<: *env-file
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: prompt_optimizer_api
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql+asyncpg://prompt_optimizer:prompt_optimizer_secret@postgres:5432/prompt_optimizer
      REDIS_URL: redis://redis:6379/0
      WEAVIATE_URL: http://weaviate:8080
      # OpenAI - Embeddings via API
      USE_LOCAL_EMBEDDINGS: "false"
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      EMBEDDING_MODEL: ${EMBEDDING_MODEL:-text-embedding-3-small}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      weaviate:
        condition: service_healthy
    volumes:
      - ../src:/app/src
    networks:
      - prompt_optimizer_network

volumes:
  postgres_data:
  redis_data:
  weaviate_data:

networks:
  prompt_optimizer_network:
    driver: bridge

